---
alwaysApply: true
---

# Fake-News Detector - Project Overview (WhatsApp Chatbot)

## 1) What this project is about

This repository is part of the broader initiative **Tá Certo Isso AI**.

The central idea:

- A **WhatsApp chatbot** that receives content from users.
- It extracts the **central claim** from text, images and links.
- It checks this claim against external information sources.
- It replies inside WhatsApp with a **verdict, short explanation and citations**.

The code in this repo supports this flow at a high level, from receiving a message to sending back an evidence based answer.

---

## 2) Problem and target users

### Problem

- Misleading and false information spreads very fast in private chats.
- Fact checking usually requires time, expertise and leaving the app.
- Many people do not have the habit or the tools to verify what they receive.

### Who we want to help

- People who rely on **WhatsApp as their main information channel**.
- Users with **limited time** or **limited media literacy**.
- Family and community group participants who want to check before forwarding.

The goal is to make **verification as simple as forwarding a message**.

---

## 3) Vision and scope

### Vision

- Turn everyday WhatsApp conversations into an **entry point for trustworthy information**.
- Use each individual fact check to build **aggregated, anonymized insights** that help society understand how misinformation circulates.

### Scope for this project

- Focus on **verifiable factual claims**, not opinions.
- Support:
  - Text only messages.
  - Images that contain text or claims.
  - Links to external content.
- Deliver a response that is:
  - Short enough for chat.
  - Clear about what was checked.
  - Transparent about the sources used.

Longer term, this project is one building block in a **broader data and analytics platform** for misinformation patterns.

---

## 4) Core experience from the user perspective

1) **Onboarding**

- The bot explains in simple language:
  - What it does.
  - What data it needs.
  - How to give consent and how to opt out.

2) **Sending content**

- The user forwards a message, image or link to the bot.
- No special technical knowledge is required.

3) **Analysis**

- The system:
  - Identifies the main claim.
  - Looks for relevant evidence.
  - Weighs the available information.

4) **Response**

- The bot returns:
  - A **verdict label** (for example: true, false, misleading, unverifiable).
  - A **short rationale**.
  - A **small list of sources** that can be opened by the user.
- The response is adapted to the chat format: concise, direct and easy to read on a phone.

5) **Follow ups**

- The user can:
  - Ask to check something else.
  - Say they disagree.
  - Ask to delete their data.
  - Ask to stop receiving analysis.

---

## 5) Principles guiding design and implementation

- **Evidence first**  
  Every verdict must be grounded in accessible sources, not in vague model opinions.

- **Clarity over complexity**  
  Users see simple labels and short texts. Any complexity stays in the internal reasoning.

- **Privacy by design**  
  Collect only what is necessary, keep it for as short as possible and make deletion easy.

- **Transparency**  
  Make it clear:
  - What was analyzed.
  - What sources were consulted.
  - Why the verdict was chosen.

- **Accessibility and inclusion**  
  Keep language simple, avoid jargon and support multilingual usage starting with Portuguese and English.

- **Graceful failure**  
  When evidence is insufficient or the system is under constraints, respond with an honest **unverifiable** result instead of guessing.

---

## 6) What “good” looks like for this repo

When working in this project, prefer:

- User centered thinking:
  - Design flows and messages starting from real WhatsApp usage.
- Simplicity:
  - Favor designs that are easy to understand, debug and maintain.
- Abstraction:
  - Separate concerns such as message handling, claim understanding, evidence search and verdict generation.
- Explicitness:
  - Make rationales, assumptions and limitations visible where it matters.

From a collaboration angle:

- Keep documentation updated enough so that a new contributor can understand:
  - What the system does end to end.
  - Where to plug new components.
- Align variable names, comments and docs with the concepts above:
  - claim, evidence, verdict, rationale, citation, consent, retention.

This file should help any AI assistant or contributor understand **intent and constraints** without needing low level details.

---

## 7) Non goals and boundaries

The following are **out of scope** for the current project definition:

- Full blown content moderation or takedown systems.
- Comprehensive deepfake detection for complex media formats.
- Cross platform bots outside WhatsApp.
- Deciding on ideological or opinion based disputes that cannot be resolved with factual evidence.

The system should be comfortable saying **“we do not know”** or **“this is not a factual claim”** instead of stretching beyond its purpose.

---

